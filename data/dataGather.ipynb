{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We connect to the spotifi API (spotipy) in order to retreive the dataset for our work. \n",
    "Let's go step by step into this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devin\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import pip \n",
    "import os\n",
    "\n",
    "# Only package not included with python\n",
    "try : \n",
    "    import spotipy\n",
    "except ImportError : \n",
    "    pip.main(['install', 'spotipy'])\n",
    "    import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to false if already have the CSVs ready\n",
    "save_csv = False\n",
    "\n",
    "# If flag set to false then csvs are loaded from cvs_dir_name searching for csvs with name \"genre.csv\" where the genres are specified in the cell below§\n",
    "grab_from_api = False\n",
    "csv_dir_name = 'csvs' \n",
    "\n",
    "# IF true after cleaning the dataset combine all the frames into a single one and save them into all_clean_path\n",
    "save_all_clean = True\n",
    "all_clean_path = 'dataframeV1.csv'\n",
    "\n",
    "# Save in separate files after cleaning, usefull for the first analysys part\n",
    "save_separate = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to focus on classic, jazz, metal and rap as we beleive those are genres that greatly differs between each other, while at the same time sharing some common gray zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['classic', 'jazz', 'metal', 'rap']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading spotify public and private key, and authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    'public' : 'e2b7e92cf8684577a314a8804b97337a', \n",
    "    'private': 'a847df678a5145d0a62381b255e4e4fd'\n",
    "    }\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=credentials['public'], client_secret=credentials['private'])\n",
    "spotyCarlo = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Clean this function \n",
    "def createFrameFromUrl(url,  carlo = spotyCarlo) : \n",
    "\n",
    "    URI = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "    offs = 0\n",
    "    feats = list()\n",
    "    \n",
    "    # Spotify Limit the number of items that it can be sent in a request to 100 so we have to loop adding offset untill empty body in response\n",
    "    while True:\n",
    "        # NOTE:  playlist_track method works only wor playlists made by users ... not genres !!!!\n",
    "        track_uris = [x[\"track\"][\"uri\"] for x in carlo.playlist_tracks(URI,offset=offs)[\"items\"]]\n",
    "        # Empty body\n",
    "        if track_uris == [] : \n",
    "            break\n",
    "        feats += carlo.audio_features(track_uris)\n",
    "        offs += 100\n",
    "    return pd.DataFrame(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'csvs\\\\classic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\devin\\Desktop\\Università\\Statistica\\SpotyProj\\spotyCARLO\\data\\dataGather.ipynb Cella 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=15'>16</a>\u001b[0m             dF_dict[genre]\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin((\u001b[39m'\u001b[39m\u001b[39mcsvs\u001b[39m\u001b[39m'\u001b[39m, genre \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=16'>17</a>\u001b[0m \u001b[39m# IF cvs already exist\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=17'>18</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=18'>19</a>\u001b[0m     dF_dict \u001b[39m=\u001b[39m {genre : pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(csv_dir_name, genre \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m), index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m genre \u001b[39min\u001b[39;00m genres}\n",
      "\u001b[1;32mc:\\Users\\devin\\Desktop\\Università\\Statistica\\SpotyProj\\spotyCARLO\\data\\dataGather.ipynb Cella 13\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=15'>16</a>\u001b[0m             dF_dict[genre]\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin((\u001b[39m'\u001b[39m\u001b[39mcsvs\u001b[39m\u001b[39m'\u001b[39m, genre \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=16'>17</a>\u001b[0m \u001b[39m# IF cvs already exist\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=17'>18</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/devin/Desktop/Universit%C3%A0/Statistica/SpotyProj/spotyCARLO/data/dataGather.ipynb#ch0000012?line=18'>19</a>\u001b[0m     dF_dict \u001b[39m=\u001b[39m {genre : pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(csv_dir_name, genre \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m), index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;00m genre \u001b[39min\u001b[39;00m genres}\n",
      "File \u001b[1;32mc:\\Users\\devin\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\devin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\devin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\devin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\devin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\devin\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'csvs\\\\classic.csv'"
     ]
    }
   ],
   "source": [
    "# We then extract the dataframes for each genre and for each playlist of the genres and save them into a dictionary. so it is easy to concatenate them\n",
    "if grab_from_api == True:\n",
    "    dF_dict = {x : [] for x in genres}\n",
    "    for genre in genres :     \n",
    "        with open(os.path.join('urls', ''.join((genre, '_url.txt'))), 'r') as f:\n",
    "            for uri in f.readlines():\n",
    "                uri = uri.strip()\n",
    "                try:\n",
    "                    dF_dict[genre].append(createFrameFromUrl(uri))\n",
    "                except : \n",
    "                    print(f\"failed on {genre}\")\n",
    "                    \n",
    "        # This will raise error if nothing were retrieved\n",
    "        dF_dict[genre] = pd.concat([x for x in dF_dict[genre]])\n",
    "        if save_csv : \n",
    "            dF_dict[genre].to_csv(os.path.join(('csvs', genre + '.csv')))\n",
    "# IF cvs already exist\n",
    "else: \n",
    "    dF_dict = {genre : pd.read_csv(os.path.join(csv_dir_name, genre + '.csv'), index_col=0) for genre in genres}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we clean the dataset from duplicates and missing values, moreover we add the label column for the genre\n",
    "def cleanFrame(dF, col_to_drop = ['track_href', 'analysis_url', 'type'], genre = '') : \n",
    "    report = {\n",
    "        'duplicate_found' : 0, \n",
    "        'NaN_found' : 0, \n",
    "        'number_of_instances' : 0,\n",
    "        'labeled' : False\n",
    "    }\n",
    "\n",
    "    i_obs, _ = dF.shape\n",
    "\n",
    "    # Dropping columns we do not need\n",
    "    fin = dF.drop(col_to_drop, axis = 1) \n",
    "\n",
    "    fin = fin.drop_duplicates(subset='id', keep = 'first')\n",
    "    d_obs, _ = fin.shape\n",
    "    report['duplicate_found'] = i_obs - d_obs\n",
    "\n",
    "    fin = fin.dropna(how = 'any')\n",
    "    n_obs, _ = fin.shape\n",
    "    report['NaN_found'] = d_obs - n_obs\n",
    "\n",
    "    report['number_of_instances'] = n_obs\n",
    "\n",
    "    if genre != '' : \n",
    "        y  = pd.DataFrame([genre for _ in range(n_obs)], columns=['genre'])\n",
    "        fin['label'] = genre\n",
    "        report['labeled'] = True\n",
    "\n",
    "    return fin, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {}\n",
    "\n",
    "\n",
    "for gen in genres : \n",
    "    dF_dict[gen], report[gen] = cleanFrame(dF_dict[gen], genre=gen)\n",
    "    if save_separate : \n",
    "        dF_dict[gen].to_csv(gen + '_cleaned.csv')\n",
    "\n",
    "if save_all_clean :\n",
    "    merged = pd.concat([dF_dict[x] for x in genres])\n",
    "    merged.to_csv(all_clean_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of classic:\n",
      "\t {'duplicate_found': 4, 'NaN_found': 0, 'number_of_instances': 244, 'labeled': True}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Report of jazz:\n",
      "\t {'duplicate_found': 18, 'NaN_found': 0, 'number_of_instances': 382, 'labeled': True}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Report of metal:\n",
      "\t {'duplicate_found': 4, 'NaN_found': 0, 'number_of_instances': 406, 'labeled': True}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Report of rap:\n",
      "\t {'duplicate_found': 5, 'NaN_found': 0, 'number_of_instances': 350, 'labeled': True}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for rep in report : \n",
    "    print(f\"Report of {rep}:\\n\\t {report[rep]}\\n\" + \"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dF = pd.read_csv('.\\csvs\\dataframeV1.csv', index_col=0)\n",
    "\n",
    "def addPop(id):\n",
    "    return spotyCarlo.track(id)['popularity']\n",
    "\n",
    "dF.insert(16,'popularity',np.array(list(map(addPop,dF.iloc[:,11]))))\n",
    "dF.to_csv('.\\csvs\\dataframeV2.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "379ef13cdaaa3488d0d0ee4a3d00b9f61dd7f8c251b8a40c38fb20881b24658a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
