{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with trees and forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree (DT) is a *non-parametric* supervised method used for both regression and classification. As the name suggests, DTs uses a tree-like model where each internal node rappresent a test on one (or more) attributes of our dataset, and each leaf node rappresent a class label; It follows that the branches rappresent the outcome of our test. The path from root to leaf are the classifications rules.\n",
    "\n",
    "![A simple rappresentation of a decision tree](imgs/simpleDT.jpg#center)\n",
    "\n",
    "\\\n",
    "Decision Trees have many advantages such as : \n",
    "* Simple to understand and even visualize\n",
    "* It is a *white box* model; Non parametric approach that is no assumption on the shape/distribution of the data\n",
    "* Can work with both numerical and categorical values\n",
    "* Easy train and fast performances\n",
    "\n",
    "\n",
    "\n",
    "On the other hand decision trees can be very sensitive to small change in the data that can result in major change in the structure of the tree; Another problem with this approach is the danger of overfitting if not taken enough precautions. \n",
    "\n",
    "\n",
    "\n",
    "**So the question is how can we can construct a decision tree?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The building process: Reducing impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm to build a decision is a 'greedy' algorithm that at each node try to find the variable that **best split** the set of items in each step. So the question becomes what is considered the best split ? \n",
    "\n",
    "Two main metrics are used nowdays : \n",
    "* Gini impurity \n",
    "* Information Gain / Entropy impurity\n",
    "\n",
    "In this brief project we decided to use the latter.\n",
    "\n",
    "In general we define the information gain as:   \n",
    "$$IG(T, \\alpha ) = H(T) - H(T| \\alpha )$$\n",
    "where $$H(X) = - \\sum^n_{i=1} P(x_i)logP(x_i)$$\n",
    "is the entropy. \n",
    "\n",
    "So when building the decision tree we are trying to reduce the conditional entropy that is equivalent to maximise the information gain on each split. In simple terms we are trying to learn $\\alpha$ such that our uncertainty about our observations is minimized. \n",
    "\n",
    "So the recursive process will be to begin with the whole dataset in the root node. We then calculate which is the best split among all features and all possible values for that feature; This will leave us with a threshold and feature on where to split. We assign to the left child of the root all observations where it's value is less or equal than the threshold and the rest to the right child. The process in then recursively repeated untill we either have all obs belonging to one class or where there are not enough observations to further split. In both cases those nodes will be the leaf nodes.\n",
    "\n",
    "\n",
    "For a more Detailed implentation refer to the **DecisionTree\\tree.py** python class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>7</td>\n",
       "      <td>-18.752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>73.289</td>\n",
       "      <td>152280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.427</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>133.630</td>\n",
       "      <td>139307</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>9</td>\n",
       "      <td>-30.790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>125.610</td>\n",
       "      <td>212067</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>2</td>\n",
       "      <td>-27.272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>79.801</td>\n",
       "      <td>365147</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>2</td>\n",
       "      <td>-16.132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>85.031</td>\n",
       "      <td>302093</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0        0.2750  0.1570    7   -18.752     1       0.0636         0.890   \n",
       "1        0.2210  0.1260    0   -25.427     1       0.0447         0.989   \n",
       "2        0.2890  0.0306    9   -30.790     0       0.0446         0.987   \n",
       "3        0.0753  0.0700    2   -27.272     1       0.0440         0.918   \n",
       "4        0.1300  0.1580    2   -16.132     1       0.0350         0.748   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  duration_ms  time_signature  \\\n",
       "0             0.842     0.186   0.3040   73.289       152280               4   \n",
       "1             0.897     0.102   0.2160  133.630       139307               4   \n",
       "2             0.911     0.102   0.1180  125.610       212067               3   \n",
       "3             0.947     0.146   0.0625   79.801       365147               4   \n",
       "4             0.924     0.100   0.0998   85.031       302093               4   \n",
       "\n",
       "   Y  \n",
       "0  0  \n",
       "1  0  \n",
       "2  0  \n",
       "3  0  \n",
       "4  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF = pd.read_csv('data//csvs//dataframeV1.csv', index_col=0)\n",
    "dF = dF.drop(['id', 'uri'], axis = 1)\n",
    "dF.label = pd.Categorical(dF.label)\n",
    "dF['Y'] = dF.label.cat.codes\n",
    "dF = dF.drop(['label'], axis = 1)\n",
    "dF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DecisionTree.tree import Tree\n",
    "\n",
    "# Creating the decision Tree\n",
    "dT = Tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for the decision tree\n",
    "y = dF.Y \n",
    "X = dF.drop([\"Y\"], axis=1)\n",
    "\n",
    "# Split in train and validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=43, train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tree on the train set \n",
    "dT.fit(x_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the prediction over the validation set\n",
    "preds = dT.predict(x_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8959537572254336"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the overall accuracy.\n",
    "sum(preds == y_test) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "379ef13cdaaa3488d0d0ee4a3d00b9f61dd7f8c251b8a40c38fb20881b24658a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
