{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with trees and forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree (DT) is a *non-parametric* supervised method used for both regression and classification. As the name suggests, DTs uses a tree-like model where each internal node rappresent a test on one (or more) attributes of our dataset, and each leaf node rappresent a class label; It follows that the branches rappresent the outcome of our test. The path from root to leaf are the classifications rules.\n",
    "\n",
    "![A simple rappresentation of a decision tree](imgs/simpleDT.jpg#center)\n",
    "\n",
    "\\\n",
    "Decision Trees have many advantages such as : \n",
    "* Simple to understand and even visualize\n",
    "* It is a *white box* model; Non parametric approach that is no assumption on the shape/distribution of the data\n",
    "* Can work with both numerical and categorical values\n",
    "* Easy train and fast performances\n",
    "\n",
    "\n",
    "\n",
    "On the other hand decision trees can be very sensitive to small change in the data that can result in major change in the structure of the tree; Another problem with this approach is the danger of overfitting if not taken enough precautions. \n",
    "\n",
    "\n",
    "\n",
    "**So the question is how can we can construct a decision tree?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The building process: Reducing impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm to build a decision is a 'greedy' algorithm that at each node try to find the variable that **best split** the set of items in each step. So the question becomes what is considered the best split ? \n",
    "\n",
    "Two main metrics are used nowdays : \n",
    "* Gini impurity \n",
    "* Information Gain / Entropy impurity\n",
    "\n",
    "In this brief project we decided to use the latter.\n",
    "\n",
    "In general we define the information gain as:   \n",
    "$$IG(T, \\alpha ) = H(T) - H(T| \\alpha )$$\n",
    "where $$H(X) = - \\sum^n_{i=1} P(x_i)logP(x_i)$$\n",
    "is the entropy. \n",
    "\n",
    "So when building the decision tree we are trying to reduce the conditional entropy that is equivalent to maximise the information gain on each split. In simple terms we are trying to learn $\\alpha$ such that our uncertainty about our observations is minimized. \n",
    "\n",
    "So the recursive process will be to begin with the whole dataset in the root node. We then calculate which is the best split among all features and all possible values for that feature; This will leave us with a threshold and feature on where to split. We assign to the left child of the root all observations where it's value is less or equal than the threshold and the rest to the right child. The process in then recursively repeated untill we either have all obs belonging to one class or where there are not enough observations to further split. In both cases those nodes will be the leaf nodes.\n",
    "\n",
    "\n",
    "For a more Detailed implentation refer to the **DecisionTree\\tree.py** python class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554</td>\n",
       "      <td>0.899</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.05210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>171.966</td>\n",
       "      <td>227893</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106</td>\n",
       "      <td>0.227</td>\n",
       "      <td>3</td>\n",
       "      <td>-15.286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.87700</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>59.940</td>\n",
       "      <td>530280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.143</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.471</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.95800</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>125.464</td>\n",
       "      <td>442227</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.337</td>\n",
       "      <td>0.209</td>\n",
       "      <td>2</td>\n",
       "      <td>-16.656</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.93500</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>89.158</td>\n",
       "      <td>185685</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402</td>\n",
       "      <td>0.873</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.00484</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>125.443</td>\n",
       "      <td>253667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.554   0.899    8    -4.573     1       0.4080       0.05210   \n",
       "1         0.106   0.227    3   -15.286     1       0.0462       0.87700   \n",
       "2         0.530   0.143    8   -17.471     1       0.0423       0.95800   \n",
       "3         0.337   0.209    2   -16.656     0       0.0314       0.93500   \n",
       "4         0.402   0.873    4    -3.209     0       0.0586       0.00484   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  duration_ms  time_signature  \\\n",
       "0          0.000000    0.0568   0.5520  171.966       227893               4   \n",
       "1          0.738000    0.1120   0.0391   59.940       530280               4   \n",
       "2          0.497000    0.2780   0.1190  125.464       442227               4   \n",
       "3          0.865000    0.1110   0.1400   89.158       185685               4   \n",
       "4          0.000073    0.1570   0.6840  125.443       253667               4   \n",
       "\n",
       "   Y  \n",
       "0  3  \n",
       "1  0  \n",
       "2  1  \n",
       "3  0  \n",
       "4  2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF = pd.read_csv('data//csvs//dataframeV1.csv', index_col=0)\n",
    "\n",
    "# Drop not usefull cols\n",
    "dF = dF.drop(['id', 'uri'], axis = 1)\n",
    "\n",
    "# Turn genres names into cat \n",
    "dF.label = pd.Categorical(dF.label)\n",
    "dF['Y'] = dF.label.cat.codes\n",
    "dF = dF.drop(['label'], axis = 1)\n",
    "\n",
    "# Shuffling the dataset\n",
    "dF = dF.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DecisionTree.tree import Tree\n",
    "\n",
    "# Creating the decision Tree\n",
    "dT = Tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for the decision tree\n",
    "\n",
    "y = dF.Y \n",
    "X = dF.drop([\"Y\"], axis=1)\n",
    "\n",
    "# Split in train and validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=43, train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tree on the train set \n",
    "dT.fit(x_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the prediction over the validation set\n",
    "preds = dT.predict(x_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930635838150289"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the overall accuracy.\n",
    "sum(preds == y_test) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to address one of the main problems when using DTs, that is overfitting. In fact is common for such models to learn on the noise and small variations in the data, if hyper-paramethers are not carefully tuned. \n",
    "\n",
    "A solution to this is to use Random Forests (RF). RF is an **ensamble learning** method that operates by constructing multiple decision trees. Many decision trees are constructed applying the general technique of bootstrapping.\n",
    "\n",
    "More formally if we have a training set $X = x_1, ..., x_n$ and the labels associated $Y = y_1, ...,y_n$ we **Bag** (Sample with replacment) from $\\{X,Y\\}$ $ B $ times and train a decision tree on this sample. We then in case of classification take the majority of votes from all the $B$ predictions as the final output of the RF model.\n",
    "\n",
    "Bootstrapping so help us solve the issue of overfitting. A step further in this direction would be modify the DT algorithm slightly, by looking at each step to only a portion of the features to find the best possible split. This not only improve the overall model accuracy and speed but also provide a further guard against overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForest.randomForest import Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first question is how many trees should build ? As there is no universal answer the best way to find out this hyperparameter is to use some model selection techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Forest ID : T13D5\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\RandomForest\\randomForest.py\", line 29, in fit\n",
      "    t_boot.fit(x_boot, y_boot)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 166, in fit\n",
      "    self.root = self._build(X,y)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 151, in _build\n",
      "    l = self._build( X[l_idx, :], y[l_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 151, in _build\n",
      "    l = self._build( X[l_idx, :], y[l_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 152, in _build\n",
      "    r = self._build(X[r_idx, :], y[r_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 152, in _build\n",
      "    r = self._build(X[r_idx, :], y[r_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 151, in _build\n",
      "    l = self._build( X[l_idx, :], y[l_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 152, in _build\n",
      "    r = self._build(X[r_idx, :], y[r_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 138, in _build\n",
      "    return Node(value = np.argmax(np.bincount(y)))\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1195, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 57, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "ValueError: attempt to get argmax of an empty sequence\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Forest ID : T14D3\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\RandomForest\\randomForest.py\", line 29, in fit\n",
      "    t_boot.fit(x_boot, y_boot)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 166, in fit\n",
      "    self.root = self._build(X,y)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 151, in _build\n",
      "    l = self._build( X[l_idx, :], y[l_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 152, in _build\n",
      "    r = self._build(X[r_idx, :], y[r_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 152, in _build\n",
      "    r = self._build(X[r_idx, :], y[r_idx], depth + 1)\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 152, in _build\n",
      "    r = self._build(X[r_idx, :], y[r_idx], depth + 1)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\benjamin.barda\\Documents\\GitHub\\spotyCARLO\\DecisionTree\\tree.py\", line 138, in _build\n",
      "    return Node(value = np.argmax(np.bincount(y)))\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1195, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"c:\\Users\\benjamin.barda\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 57, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "ValueError: attempt to get argmax of an empty sequence\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Forest ID : T14D5\r"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'max_trees' : [x for x in range(5,15)],\n",
    "    'max_detph' : [2,3,4,5]\n",
    "}\n",
    "\n",
    "K = 10\n",
    "\n",
    "\n",
    "res_acc = {}\n",
    "res_time = {}\n",
    "for b in parameters['max_trees']: \n",
    "    res_acc['T' + str(b)] = list()\n",
    "    res_time['T' + str(b)] = list()\n",
    "    for d in parameters['max_detph']:\n",
    "        print(f\"Fitting Forest ID : T{b}D{d}\", end = '\\r')\n",
    "        score = cross_validate(Forest(max_trees=b, max_depth=6), X, y, scoring='accuracy', cv = K, n_jobs=-1 )\n",
    "        res_acc['T' + str(b)].append(sum(score['test_score']) / K)\n",
    "        res_time['T' + str(b)].append(sum(score['score_time']) / K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>(0.8525857574809717, 0.0030984878540039062)</td>\n",
       "      <td>(0.8735481180273172, 0.0029839515686035157)</td>\n",
       "      <td>(0.846950265874257, 0.0036997318267822264)</td>\n",
       "      <td>(0.8894588676884579, 0.0035001039505004883)</td>\n",
       "      <td>(0.888098217078511, 0.0041046142578125)</td>\n",
       "      <td>(0.8916536336148472, 0.004701352119445801)</td>\n",
       "      <td>(0.8888176415389427, 0.005103921890258789)</td>\n",
       "      <td>(0.8880512980919614, 0.0052003622055053714)</td>\n",
       "      <td>(0.8858930247106661, 0.005707049369812011)</td>\n",
       "      <td>(0.8750495255969136, 0.006203079223632812)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.8829788343238454, 0.002597355842590332)</td>\n",
       "      <td>(0.8764310290897714, 0.0029999732971191405)</td>\n",
       "      <td>(0.8743248879157545, 0.003403496742248535)</td>\n",
       "      <td>(0.8757585236158899, 0.0037553071975708007)</td>\n",
       "      <td>(0.856318423522052, 0.003993701934814453)</td>\n",
       "      <td>(0.8749765405067249, 0.004492855072021485)</td>\n",
       "      <td>(0.8721666145344594, 0.005800676345825195)</td>\n",
       "      <td>(0.8902408507976227, 0.005205631256103516)</td>\n",
       "      <td>(0.891705765822125, 0.006191158294677734)</td>\n",
       "      <td>(nan, 0.005389022827148438)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.8606349702846419, 0.0022997617721557616)</td>\n",
       "      <td>(0.8467834428109686, 0.003395342826843262)</td>\n",
       "      <td>(0.8858200396204776, 0.0035976409912109376)</td>\n",
       "      <td>(0.8895057866750079, 0.0037070751190185548)</td>\n",
       "      <td>(0.8620842456469606, 0.004105663299560547)</td>\n",
       "      <td>(0.8656709415076633, 0.0043030261993408205)</td>\n",
       "      <td>(0.8707642581586903, 0.00509953498840332)</td>\n",
       "      <td>(0.8750390991554582, 0.005202579498291016)</td>\n",
       "      <td>(0.9010687102491918, 0.00579991340637207)</td>\n",
       "      <td>(0.8851058283807737, 0.006003069877624512)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.8649358773850485, 0.0024002552032470702)</td>\n",
       "      <td>(0.8778646647899071, 0.003002429008483887)</td>\n",
       "      <td>(0.8750286727140028, 0.0035003900527954103)</td>\n",
       "      <td>(0.8836878323428214, 0.0036047220230102537)</td>\n",
       "      <td>(0.8844750286727139, 0.004000663757324219)</td>\n",
       "      <td>(0.8655979564174745, 0.004393911361694336)</td>\n",
       "      <td>(0.8945156917943906, 0.0047978639602661135)</td>\n",
       "      <td>(0.8685382129079345, 0.0054590702056884766)</td>\n",
       "      <td>(nan, 0.005699920654296875)</td>\n",
       "      <td>(0.8880825774163277, 0.005752372741699219)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth                                           T5  \\\n",
       "0      2  (0.8525857574809717, 0.0030984878540039062)   \n",
       "1      3   (0.8829788343238454, 0.002597355842590332)   \n",
       "2      4  (0.8606349702846419, 0.0022997617721557616)   \n",
       "3      5  (0.8649358773850485, 0.0024002552032470702)   \n",
       "\n",
       "                                            T6  \\\n",
       "0  (0.8735481180273172, 0.0029839515686035157)   \n",
       "1  (0.8764310290897714, 0.0029999732971191405)   \n",
       "2   (0.8467834428109686, 0.003395342826843262)   \n",
       "3   (0.8778646647899071, 0.003002429008483887)   \n",
       "\n",
       "                                            T7  \\\n",
       "0   (0.846950265874257, 0.0036997318267822264)   \n",
       "1   (0.8743248879157545, 0.003403496742248535)   \n",
       "2  (0.8858200396204776, 0.0035976409912109376)   \n",
       "3  (0.8750286727140028, 0.0035003900527954103)   \n",
       "\n",
       "                                            T8  \\\n",
       "0  (0.8894588676884579, 0.0035001039505004883)   \n",
       "1  (0.8757585236158899, 0.0037553071975708007)   \n",
       "2  (0.8895057866750079, 0.0037070751190185548)   \n",
       "3  (0.8836878323428214, 0.0036047220230102537)   \n",
       "\n",
       "                                           T9  \\\n",
       "0     (0.888098217078511, 0.0041046142578125)   \n",
       "1   (0.856318423522052, 0.003993701934814453)   \n",
       "2  (0.8620842456469606, 0.004105663299560547)   \n",
       "3  (0.8844750286727139, 0.004000663757324219)   \n",
       "\n",
       "                                           T10  \\\n",
       "0   (0.8916536336148472, 0.004701352119445801)   \n",
       "1   (0.8749765405067249, 0.004492855072021485)   \n",
       "2  (0.8656709415076633, 0.0043030261993408205)   \n",
       "3   (0.8655979564174745, 0.004393911361694336)   \n",
       "\n",
       "                                           T11  \\\n",
       "0   (0.8888176415389427, 0.005103921890258789)   \n",
       "1   (0.8721666145344594, 0.005800676345825195)   \n",
       "2    (0.8707642581586903, 0.00509953498840332)   \n",
       "3  (0.8945156917943906, 0.0047978639602661135)   \n",
       "\n",
       "                                           T12  \\\n",
       "0  (0.8880512980919614, 0.0052003622055053714)   \n",
       "1   (0.8902408507976227, 0.005205631256103516)   \n",
       "2   (0.8750390991554582, 0.005202579498291016)   \n",
       "3  (0.8685382129079345, 0.0054590702056884766)   \n",
       "\n",
       "                                          T13  \\\n",
       "0  (0.8858930247106661, 0.005707049369812011)   \n",
       "1   (0.891705765822125, 0.006191158294677734)   \n",
       "2   (0.9010687102491918, 0.00579991340637207)   \n",
       "3                 (nan, 0.005699920654296875)   \n",
       "\n",
       "                                          T14  \n",
       "0  (0.8750495255969136, 0.006203079223632812)  \n",
       "1                 (nan, 0.005389022827148438)  \n",
       "2  (0.8851058283807737, 0.006003069877624512)  \n",
       "3  (0.8880825774163277, 0.005752372741699219)  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame.from_dict(res_acc, orient='columns')\n",
    "acc_df = pd.concat([pd.Series(parameters['max_detph'], name = 'Depth'),acc_df], axis = 1)\n",
    "\n",
    "time_df = pd.DataFrame.from_dict(res_time, orient='columns')\n",
    "time_df = pd.concat([pd.Series(parameters['max_detph'], name = 'Depth'),time_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "save = True\n",
    "\n",
    "\n",
    "if save:\n",
    "    with open('cv_acc_res.txt', 'w') as f: \n",
    "        acc_df.to_csv(f)\n",
    "        f.close()\n",
    "    with open('cv_time_res.txt', 'w') as f: \n",
    "        time_df.to_csv(f)\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "met.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949ca02c6f6c8e46594f49d827909bb6cc1f655ba57a65a49f724deda5e66916"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
