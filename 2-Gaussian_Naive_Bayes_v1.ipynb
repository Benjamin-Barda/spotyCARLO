{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Imports](#import)\n",
    "2. [Function for reading the csv files and dropping the unwanted columns](#readfile)\n",
    "3. [Standardize the data](#standardise)\n",
    "4. [Confusion Matrix, Classification Report and Accuracy Report](#confusionmatrix)\n",
    "5. [Explanation of k-means and k-means++](#exp)\n",
    "6. [Naive Bayes Classifier Explanation](#naive)\n",
    "7. [Gaussian Naive Bayes Explanation](#gaus)\n",
    "8. [Getiing the MLE for the Mean and the Variance](#mle)\n",
    "9. [Naive Bayes Classifier Implementation](#impnaive)\n",
    "10. [Plot the Confusion Matrix and print the Classification Report and Accuracy Score](#conf)\n",
    "11. [Train and Prediction](#train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"import\"></a> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"readfile\"></a> Function for reading the csv files and dropping the unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 3 3 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>7</td>\n",
       "      <td>-18.752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.89000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>73.289</td>\n",
       "      <td>4</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.427</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.98900</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>133.630</td>\n",
       "      <td>4</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>9</td>\n",
       "      <td>-30.790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.98700</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>125.610</td>\n",
       "      <td>3</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>2</td>\n",
       "      <td>-27.272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.91800</td>\n",
       "      <td>0.947000</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>79.801</td>\n",
       "      <td>4</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>2</td>\n",
       "      <td>-16.132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.74800</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>85.031</td>\n",
       "      <td>4</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.44600</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>139.526</td>\n",
       "      <td>4</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>7</td>\n",
       "      <td>-7.821</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.12100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>141.060</td>\n",
       "      <td>4</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.00422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>99.095</td>\n",
       "      <td>4</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.631</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>139.920</td>\n",
       "      <td>4</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>10</td>\n",
       "      <td>-11.607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.37900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>142.079</td>\n",
       "      <td>4</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.2750  0.1570    7   -18.752     1       0.0636       0.89000   \n",
       "1         0.2210  0.1260    0   -25.427     1       0.0447       0.98900   \n",
       "2         0.2890  0.0306    9   -30.790     0       0.0446       0.98700   \n",
       "3         0.0753  0.0700    2   -27.272     1       0.0440       0.91800   \n",
       "4         0.1300  0.1580    2   -16.132     1       0.0350       0.74800   \n",
       "..           ...     ...  ...       ...   ...          ...           ...   \n",
       "45        0.6510  0.7610   10    -7.801     1       0.2500       0.44600   \n",
       "46        0.8710  0.6390    7    -7.821     1       0.3490       0.12100   \n",
       "47        0.6170  0.4770    1    -9.889     1       0.3600       0.00422   \n",
       "48        0.8500  0.5640    1    -9.631     0       0.3830       0.23800   \n",
       "49        0.7360  0.5180   10   -11.607     0       0.4680       0.37900   \n",
       "\n",
       "    instrumentalness  liveness  valence    tempo  time_signature    label  \n",
       "0           0.842000    0.1860   0.3040   73.289               4  classic  \n",
       "1           0.897000    0.1020   0.2160  133.630               4  classic  \n",
       "2           0.911000    0.1020   0.1180  125.610               3  classic  \n",
       "3           0.947000    0.1460   0.0625   79.801               4  classic  \n",
       "4           0.924000    0.1000   0.0998   85.031               4  classic  \n",
       "..               ...       ...      ...      ...             ...      ...  \n",
       "45          0.000035    0.1110   0.8690  139.526               4      rap  \n",
       "46          0.000000    0.1930   0.7640  141.060               4      rap  \n",
       "47          0.000000    0.0830   0.4360   99.095               4      rap  \n",
       "48          0.000000    0.1110   0.3480  139.920               4      rap  \n",
       "49          0.000000    0.0989   0.7710  142.079               4      rap  \n",
       "\n",
       "[1382 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = ['id', 'uri', 'duration_ms']\n",
    "file_name = r\"data\\csvs\\dataframeV1.csv\"\n",
    "\n",
    "def read_csv_files(file_name, cols_to_drop=cols_to_drop): \n",
    "    df = pd.read_csv(file_name, index_col=0)\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    labels = df['label']\n",
    "    \n",
    "    # This makes the categorical labels numbers. Print it to see... Better than labels.cat.codes\n",
    "    y = labels.factorize()[0]\n",
    "    \n",
    "    # Add new axis to y in order to be able to transpose it when needed \n",
    "    # y = y[:, np.newaxis]\n",
    "    return df, y\n",
    "\n",
    "df, y = read_csv_files(file_name)\n",
    "print(y)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"standardise\"></a> Standardize the data\n",
    "\n",
    "We can drop the labels of our training data and then convert them on a single scale. We can standardize the values using the below formula.\n",
    "\n",
    "$$x_i = \\frac{{x}_i - mean(x)} {\\sigma(x)} $$\n",
    "\n",
    "Itâ€™s recommended to standardize the data to have a mean of zero and a standard deviation of one since almost always the features in any dataset would have different units of measurements such as age vs income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.100925</td>\n",
       "      <td>-1.050292</td>\n",
       "      <td>0.511531</td>\n",
       "      <td>-0.834979</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>-0.373430</td>\n",
       "      <td>1.090495</td>\n",
       "      <td>1.715003</td>\n",
       "      <td>0.113724</td>\n",
       "      <td>-0.370043</td>\n",
       "      <td>-1.362347</td>\n",
       "      <td>0.252684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.368146</td>\n",
       "      <td>-1.141622</td>\n",
       "      <td>-1.470268</td>\n",
       "      <td>-1.661467</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>-0.563558</td>\n",
       "      <td>1.329736</td>\n",
       "      <td>1.869971</td>\n",
       "      <td>-0.530812</td>\n",
       "      <td>-0.735956</td>\n",
       "      <td>0.579970</td>\n",
       "      <td>0.252684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.031645</td>\n",
       "      <td>-1.422685</td>\n",
       "      <td>1.077759</td>\n",
       "      <td>-2.325506</td>\n",
       "      <td>-1.106597</td>\n",
       "      <td>-0.564564</td>\n",
       "      <td>1.324903</td>\n",
       "      <td>1.909417</td>\n",
       "      <td>-0.530812</td>\n",
       "      <td>-1.143451</td>\n",
       "      <td>0.321814</td>\n",
       "      <td>-1.850984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.089151</td>\n",
       "      <td>-1.306607</td>\n",
       "      <td>-0.904040</td>\n",
       "      <td>-1.889913</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>-0.570600</td>\n",
       "      <td>1.158159</td>\n",
       "      <td>2.010851</td>\n",
       "      <td>-0.193198</td>\n",
       "      <td>-1.374226</td>\n",
       "      <td>-1.152733</td>\n",
       "      <td>0.252684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.818465</td>\n",
       "      <td>-1.047346</td>\n",
       "      <td>-0.904040</td>\n",
       "      <td>-0.510575</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>-0.661137</td>\n",
       "      <td>0.747340</td>\n",
       "      <td>1.946046</td>\n",
       "      <td>-0.546158</td>\n",
       "      <td>-1.219128</td>\n",
       "      <td>-0.984384</td>\n",
       "      <td>0.252684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy       key  loudness      mode  speechiness  \\\n",
       "0     -1.100925 -1.050292  0.511531 -0.834979  0.903018    -0.373430   \n",
       "1     -1.368146 -1.141622 -1.470268 -1.661467  0.903018    -0.563558   \n",
       "2     -1.031645 -1.422685  1.077759 -2.325506 -1.106597    -0.564564   \n",
       "3     -2.089151 -1.306607 -0.904040 -1.889913  0.903018    -0.570600   \n",
       "4     -1.818465 -1.047346 -0.904040 -0.510575  0.903018    -0.661137   \n",
       "\n",
       "   acousticness  instrumentalness  liveness   valence     tempo  \\\n",
       "0      1.090495          1.715003  0.113724 -0.370043 -1.362347   \n",
       "1      1.329736          1.869971 -0.530812 -0.735956  0.579970   \n",
       "2      1.324903          1.909417 -0.530812 -1.143451  0.321814   \n",
       "3      1.158159          2.010851 -0.193198 -1.374226 -1.152733   \n",
       "4      0.747340          1.946046 -0.546158 -1.219128 -0.984384   \n",
       "\n",
       "   time_signature  \n",
       "0        0.252684  \n",
       "1        0.252684  \n",
       "2       -1.850984  \n",
       "3        0.252684  \n",
       "4        0.252684  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"label\"], axis=1)\n",
    "\n",
    "def standardise(X):\n",
    "    # mean and standard deviation of all the features irrespective of class differences\n",
    "    mean_all   = X.mean()  \n",
    "    std_all    = X.std() \n",
    "\n",
    "    # standardised values\n",
    "    X_standardised = (X-mean_all)/std_all\n",
    "    return X_standardised\n",
    "\n",
    "X_standardised = standardise(X)\n",
    "\n",
    "X_standardised.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"naive\"></a> Naive Bayes Classifier. \n",
    "Let's first get to know the calculations before the actual implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of feature values, where the class labels are drawn from some finite set. There is not a single algorithm for training such classifiers, but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable. For example, a fruit may be considered to be an apple if it is red, round, and about 10 cm in diameter. A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple, regardless of any possible correlations between the color, roundness, and diameter features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstractly, naive Bayes is a conditional probability model: given a problem instance to be classified, represented by a vector $ {\\displaystyle \\mathbf {x} =(x_{1},\\ldots ,x_{n})}$ representing some n features (independent variables), it assigns to this instance probabilities\n",
    "$$ {\\LARGE{ \\displaystyle p(C_{k}\\mid x_{1},\\ldots ,x_{n})\\,}}$$\n",
    "for each of K possible outcomes or classes ${\\displaystyle C_{k}}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using Bayes' theorem, the conditional probability can be decomposed as\n",
    "$$ {\\displaystyle p(C_{k}\\mid \\mathbf {x} )={\\frac {p(C_{k})\\ p(\\mathbf {x} \\mid C_{k})}{p(\\mathbf {x} )}}\\,} $$\n",
    "In plain English, using Bayesian probability terminology, the above equation can be written as\n",
    "$$ {\\displaystyle {\\text{posterior}}={\\frac {{\\text{prior}}\\times {\\text{likelihood}}}{\\text{evidence}}}\\,} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, there is interest only in the numerator of that fraction, because the denominator does not depend on ${\\displaystyle C}$ and the values of the features $\\mathbf{x_{i}}$ are given, so that the denominator is effectively constant. So the evidence,\n",
    "$ {\\displaystyle \\sum _{k}p(C_{k})\\ p(\\mathbf {x} \\mid C_{k})}$\n",
    "is a scaling factor dependent only on ${\\displaystyle x_{1},\\ldots ,x_{n}}$, that is, a constant if the values of the feature variables are known. So we shall drop it since it does not influence the classification.\n",
    "\n",
    "Again, in our case, since we have four classes each of which occuring with equal probability of $\\frac{1}{4}$, we can see that the **prior**, $\\mathbb{P}(\\mathbf{C}_k)$, is effectively constant just like the evidence above. So, we shall drop it as well.\n",
    "\n",
    "\n",
    "Now we have only the **likelihood**, $p(\\mathbf {x} \\mid C_{k})$ , to work with. The likelihood can be rewritten as follows, using the chain rule for repeated applications of the definition of conditional probability:\n",
    "\n",
    "$$\\displaystyle{p(x_1, x_2, \\ldots, x_n \\mid C_k) = p(x_{1}\\mid x_{2},\\ldots ,x_{n},C_{k})\\ p(x_{2}\\mid x_{3},\\ldots ,x_{n},C_{k})\\cdots p(x_{n-1}\\mid x_{n},C_{k})\\ p(x_{n}\\mid C_{k})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the **naive** conditional independence assumptions come into play: assume that all features in $\\mathbf{x}$ are mutually independent, conditional on the category $\\mathbf{C_{k}}$. Under this assumption,\n",
    "\n",
    "$$\\displaystyle {p(x_{i}\\mid x_{i+1},\\ldots ,x_{n},C_{k})=p(x_{i}\\mid C_{k})\\,}.$$\n",
    "\n",
    "Thus, the joint model, after dropping the prior and the evidence, can be expressed as **proportional** to $\\prod _{i=1}^{n}p(x_{i}\\mid C_{k})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Distribution should we use for the joint model **proportional** to $\\prod _{i=1}^{n}p(x_{i}\\mid C_{k})$? Even though there are many distributions to use here, we opt for Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"gaus\"></a> Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with continuous data, a typical assumption is that the continuous values associated with each class are distributed according to a normal (or Gaussian) distribution. For example, suppose the training data contains a continuous attribute, $\\mathbf{x}$. The data is first **segmented** by the class, and then the **mean** and **variance** of $\\mathbf{x}$ is computed in each class. Let $\\mathbf{\\mu _{k}}$ be the mean of the values in $\\mathbf{x}$ associated with class $\\mathbf{C}_k $, and let $\\mathbf{\\sigma}_{k}^{2}$ be the unbiased sample variance of the values in $\\mathbf{x}$ associated with class $\\mathbf{C}_k $ (that is, the degree of freedom is 1 => n-1). Suppose one has collected some observation value v. Then, the probability density of v given a class $\\mathbf{C}_k $, $\\displaystyle{p(x=v\\mid C_{k})}$, can be computed by plugging v into the equation for a normal distribution parameterized by $\\displaystyle{\\mu _{k}}$ and $\\displaystyle{\\sigma _{k}^{2}}$ as thus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\LARGE{ \\mathbb{P}(\\mathbf{X} = x | \\mathbb{C_k}) = \\frac{1}{\\sqrt{2\\pi\\sigma_{k}^{2}}} \\LARGE{e^{- \\frac{(x-\\mu_k)^2}{2\\sigma_{k}^{2}}}} }\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to classify samples, one has to determine which posterior is greater: classic, jazz, metal or rap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for the classification as rap the posterior is given by\n",
    "\n",
    "$$ \\text{posterior(rap)} = \\frac{\\mathbb{P}(\\text{rap})\\mathbb{P}(\\text{danceability|rap})...\\mathbb{P}(\\text{tempo|rap})\\mathbb{P}(\\text{timeSignature|rap})}{\\text{evidence}} $$\n",
    "where the\n",
    "\n",
    "$$ \\begin{align}\n",
    "evidence &= \\mathbb{P}(\\text{classic})\\mathbb{P}(\\text{danceability|classic})...\\mathbb{P}(\\text{timeSignature|classic}) \\\\\n",
    "        &+ \\mathbb{P}(\\text{jazz})\\mathbb{P}(\\text{danceability|jazz})...\\mathbb{P}(\\text{timeSignature|jazz})\\\\\n",
    "        &+ \\mathbb{P}(\\text{metal})\\mathbb{P}(\\text{danceability|metal})...\\mathbb{P}(\\text{timeSignature|metal}) \\\\\n",
    "        &+ \\mathbb{P}(\\text{rap})\\mathbb{P}(\\text{danceability|rap})...\\mathbb{P}(\\text{timeSignature|rap}) \n",
    "\\end{align}$$\n",
    "and prior = $\\frac{1}{4}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since we know that the evidence and the prior are effectively constants, we can drop them as already explained above. Thus:\n",
    "\n",
    "- posterior(classic) = $\\mathbb{P}(\\text{danceability|classic}) \\dots \\mathbb{P}(\\text{tempo|classic})\\mathbb{P}(\\text{timeSignature|classic})$\n",
    "- posterior(jazz) = $\\mathbb{P}(\\text{danceability|jazz})\\dots \\mathbb{P}(\\text{timeSignature|jazz})$\n",
    "- posterior(metal) = $\\mathbb{P}(\\text{danceability|metal})\\dots \\mathbb{P}(\\text{timeSignature|metal})$ \n",
    "- posterior(rap) = $\\mathbb{P}(\\text{danceability|rap})\\dots \\mathbb{P}(\\text{tempo|rap})\\mathbb{P}(\\text{timeSignature|rap})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ```negative log-likelihood``` since the product of a large number of small probabilities can easily underflow the numerical precision of the computer. And this is resolved by computing instead the sum of the negative log probabilities as thus:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\large{-log\\prod _{i=1}^{N}p(x_{i}\\mid C_{k}) }\n",
    "&=  \\large{ \\sum_{i=1}^N -log \\left( \\mathbb{P}(\\mathbf{X} = x_i | \\mathbb{C_k} \\right)} \\\\\n",
    "&=  \\large{ \\sum_{i=1}^N -log \\left(\\frac{1}{\\sqrt{2\\pi\\sigma_{j,k}^{2}}}e^{- \\large{ \\frac{(x_i -\\mu_{j,k})^2}{2\\sigma_{j,k}^{2}}}} \\right) }\\\\\n",
    "&= \\large{ \\sum_{i=1}^N \\frac{1}{2}log \\left(2\\pi\\sigma_{j,k}^2\\right) + \\frac{(x_i -\\mu_{j,k})^2}{2\\sigma_{j,k}^{2}} }\n",
    "\\end{align}$$\n",
    "\n",
    "Where k is the class label and j is the index of the feature at column j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"mle\"></a> Getiing the MLE for the Mean and the Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```LOG-LIKELIHOOD```  =  $\\mathbf{\\ell}(\\mu_{(j,k)}, \\sigma_{(j,k)}^2) = -\\frac{1}{2}\\sum_{i=1}^N log(2\\pi) -\\sum_{i=1}^N log \\left(\\sigma_{j,k}\\right) -\\frac{1}{2} \\sum_{i=1}^N \\frac{(x_i -\\mu_{j,k})^2}{\\sigma_{j,k}^{2}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```MEAN```:\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\frac{\\partial \\ell}{\\partial \\mu_{j,k}} &= -\\frac{1}{2} \\sum_{i=1}^N \\frac{2}{\\sigma_{j,k}^2} (x_i -\\mu_{j,k})(-1) = 0 \\\\\n",
    "&\\implies \\sum_{i=1}^N \\frac{x_i - \\mu_{j,k}}{\\sigma_{j,k}^2} = 0 \\\\\n",
    "&\\implies \\frac{1}{\\sigma_{j,k}^2} \\sum_{i=1}^N x_i   -\\frac{1}{\\sigma_{j,k}^2} \\sum_{i=1}^N \\mu_{j,k} = 0 \\\\\n",
    "&\\implies \\sum_{i=1}^N \\mu_{j,k} = \\sum_{i=1}^N x_i \\\\\n",
    "&\\implies \\mu_{j,k} = \\frac{1}{N}\\sum_{i=1}^N x_i\n",
    "\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```VARIANCE```:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial \\ell}{\\partial \\sigma_{j,k}^2} &= -\\sum_{i=1}^N \\frac{1}{\\sigma_{j,k}} + \\sum_{i=1}^N \\frac{(x_i - \\mu_{j,k})^2}{\\sigma_{j,k}^3} = 0 \\\\\n",
    "& \\implies \\frac{-N}{\\sigma_{j,k}} + \\frac{1}{\\sigma_{j,k}^3} \\sum_{i=1}^N (x_i - \\mu_{j,k})^2 = 0 \\\\\n",
    "& \\implies \\frac{1}{\\sigma_{j,k}^3} \\sum_{i=1}^N (x_i - \\mu_{j,k})^2 = \\frac{N}{\\sigma_{j,k}} \\\\\n",
    "& \\implies \\sigma_{j,k}^2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu_{j,k})^2\n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the best estimate for the mean and variance parameters of a Gaussian are simply the empirical estimates of the mean and variance respectively. These means and variances are for each feature w.r.t each class. For example, the feature danceability w.r.t rap has a mean and variance different than danceability w.r.t classic. So for each feature x, it has a mean and variance for each class c.Therefore, the means and variances must be calculated for each feature (in our case, a whopping 12 features for 4 classes). We did this in a simple one-pass by first filtering out the appropriate instances (w.r.t to the class in question) under each feature, then take the mean and variance as can be seen in the implementation below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"impnaive\"></a> Implementation of the fit and predict methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GaussNaiveBayes(): \n",
    "    def __init__(self):\n",
    "        \n",
    "        #To check if the \"fit\" method is called to initialize all variables before calling the predict.\n",
    "        self.__run_fit_first = False\n",
    "        \n",
    "    ##############################################################################Ã \n",
    "    def fit(self, X, y):        \n",
    "        classes = {\"classic\": 0, \"jazz\": 1, \"metal\": 2, \"rap\": 3}\n",
    "        \n",
    "        # Notice that these are dictionaries, rather than lists. e.g. mean_classic[\"danceability\"]\n",
    "        self.mean_classic   = self.__values_of_each_label(X, y, classes[\"classic\"]).mean(numeric_only=True)  \n",
    "        self.mean_jazz      = self.__values_of_each_label(X, y, classes[\"jazz\"]).mean(numeric_only=True)\n",
    "        self.mean_metal     = self.__values_of_each_label(X, y, classes[\"metal\"]).mean(numeric_only=True)\n",
    "        self.mean_rap       = self.__values_of_each_label(X, y, classes[\"rap\"]).mean(numeric_only=True)\n",
    "        \n",
    "        #degree of freedom = 1 => (n-1)\n",
    "        self.variance_classic   = self.__values_of_each_label(X, y, classes[\"classic\"]).var(numeric_only=True, ddof=1)  \n",
    "        self.variance_jazz      = self.__values_of_each_label(X, y, classes[\"jazz\"]).var(numeric_only=True, ddof=1)\n",
    "        self.variance_metal     = self.__values_of_each_label(X, y, classes[\"metal\"]).var(numeric_only=True, ddof=1)\n",
    "        self.variance_rap       = self.__values_of_each_label(X, y, classes[\"rap\"]).var(numeric_only=True, ddof=1)\n",
    "        \n",
    "        #Set it to True since all the required variables have been initialized\n",
    "        self.__run_fit_first = True\n",
    "        \n",
    "    def __values_of_each_label(self, X, y, labl):\n",
    "        t = np.where(y == labl)  \n",
    "        vals = X.iloc[t]\n",
    "        return vals\n",
    "    \n",
    "    ######################################################################################Ã \n",
    "    def predict(self, X_test): \n",
    "        \n",
    "        #Raise an error message if the fit method has not been called first to initialize variables.\n",
    "        assert self.__run_fit_first == True, \"Please, run the 'fit' method first to train the model!.\"\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        if len(X_test) > 1:\n",
    "            for row in X_test.values:\n",
    "                pred = self.__prob_of_feature_given_label(row)\n",
    "                m = np.argmin([pred[\"classic\"], pred[\"jazz\"], pred[\"metal\"], pred[\"rap\"]])\n",
    "                predictions.append(m)\n",
    "                \n",
    "        #for testing single row\n",
    "        elif len(X_test) == 1:\n",
    "            pred = self.__prob_of_feature_given_label(X_test)\n",
    "            m = np.argmin([pred[\"classic\"], pred[\"jazz\"], pred[\"metal\"], pred[\"rap\"]])\n",
    "            predictions.append(m)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "        \n",
    "    def __prob_of_feature_given_label(self, row):\n",
    "        probs = {\"classic\": 0, \"jazz\": 0, \"metal\": 0, \"rap\": 0}\n",
    "        \n",
    "        for i, val in enumerate(row):\n",
    "            probs[\"classic\"] += self.__gauss_func(val, self.mean_classic.iloc[i], self.variance_classic.iloc[i])\n",
    "            probs[\"jazz\"]   +=  self.__gauss_func(val, self.mean_jazz.iloc[i], self.variance_jazz.iloc[i]) \n",
    "            probs[\"metal\"]  +=  self.__gauss_func(val, self.mean_metal.iloc[i], self.variance_metal.iloc[i]) \n",
    "            probs[\"rap\"]    +=  self.__gauss_func(val, self.mean_rap.iloc[i], self.variance_rap.iloc[i])\n",
    "            #print(probs)\n",
    "            \n",
    "        return probs\n",
    "        \n",
    "    # After taking log of the Gaussian distribution\n",
    "    def __gauss_func(self, val, mu, sigma): \n",
    "        v = (val-mu)**2\n",
    "        s =  2*sigma**2\n",
    "        power = v/s                                # (x-mean)^2 / 2sigma^2 after taking the log\n",
    "        \n",
    "        scale = 0.5*np.log(2*np.pi*sigma**2)       # 0.5*ln(2pi*sigma^2) after taking the log\n",
    "        \n",
    "        return scale+power\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_standardised, y, stratify=y, shuffle=True, random_state=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"conf\"></a> Plot the Confusion Matrix and print the Classification Report and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [\"Classic\", \"Jazz\", \"Metal\", \"Rap\"]\n",
    "\n",
    "def confusion_matrix_score(ytest, ypred, labels=labels):\n",
    "    \n",
    "    score = accuracy_score(ytest, ypred) * 100\n",
    "    print(f\"The accuracy score is {score:.2f}%.\", end=\"\\n\\n\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(ytest, ypred)\n",
    "\n",
    "    sns.heatmap(conf_matrix, square=True, annot=True, fmt='d', cbar=True, lw=0.6,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels)\n",
    "\n",
    "    plt.title(\"Confusion Matrix\", color=\"blue\", fontsize=25)\n",
    "\n",
    "    plt.xlabel('True Label')\n",
    "    plt.ylabel('Predicted Label');\n",
    "\n",
    "    # classification_report\n",
    "    print(f\"classification_report: \\n{ classification_report(ytest, ypred, target_names=labels) }\", end=\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"train\"></a> Train and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 89.02%.\n",
      "\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Classic       0.88      0.85      0.87        61\n",
      "        Jazz       0.88      0.89      0.88        96\n",
      "       Metal       0.94      0.89      0.91       102\n",
      "         Rap       0.86      0.92      0.89        87\n",
      "\n",
      "    accuracy                           0.89       346\n",
      "   macro avg       0.89      0.89      0.89       346\n",
      "weighted avg       0.89      0.89      0.89       346\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "GNB = GaussNaiveBayes()\n",
    "\n",
    "GNB.fit(X_train, y_train)\n",
    "y_pred = GNB.predict(X_test)\n",
    "\n",
    "confusion_matrix_score(y_test, y_pred)\n",
    "\n",
    "# for i in list( zip(y_test, y_pred)):\n",
    "#     print(i, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sk-learn library implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 91.33%.\n",
      "\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Classic       0.93      0.85      0.89        61\n",
      "        Jazz       0.88      0.86      0.87        96\n",
      "       Metal       0.94      0.96      0.95       102\n",
      "         Rap       0.90      0.95      0.93        87\n",
      "\n",
      "    accuracy                           0.91       346\n",
      "   macro avg       0.91      0.91      0.91       346\n",
      "weighted avg       0.91      0.91      0.91       346\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_2 = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix_score(y_test, y_pred_2)\n",
    "\n",
    "# for i in list( zip(y_pred_2, y_pred)):\n",
    "#     print(i, end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b1c34a4705f1ad3e989dda6439809041f8cc2de32377149232f1be5f4f19a59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
